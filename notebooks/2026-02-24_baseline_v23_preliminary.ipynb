{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-overview",
   "metadata": {},
   "source": "# Experiment: Baseline U-Net v2.3 Pipeline Validation\n\n**Date:** 2026-02-24  \n**Experiment ID:** `baseline_v23`  \n**Status:** Preliminary (seed 42 only; seeds 123/456 pending)  \n**Type:** Training  \n**GitHub Issue:** [#37](https://github.com/wrockey/vmat-diffusion/issues/37)  \n\n---\n\n## 1. Overview\n\n### 1.1 Objective\n\nValidate the full training-inference-evaluation pipeline end-to-end on v2.3 preprocessed data (74 cases). This is the first experiment on the work machine with the corrected preprocessing pipeline (D95 artifact fix, #4). The primary goal is **pipeline validation**, with secondary goals of establishing preliminary v2.3 baseline metrics and identifying issues before the Phase 2 ablation study.\n\n### 1.2 Key Results (Seed 42 Only — PRELIMINARY)\n\n| Metric | Value | Target | Status |\n|--------|-------|--------|--------|\n| PTV70 D95 \\|error\\| | **1.01 \\u00b1 0.76 Gy** | < 2 Gy | 6/7 pass |\n| PTV-region Gamma 3%/3mm | **85.5 \\u00b1 10.9%** | > 95% | Close |\n| QUANTEC compliance | **4/7 cases (57%)** | > 90% | Dmax hotspots only |\n| MAE | 4.80 \\u00b1 2.45 Gy | diagnostic | — |\n| Global Gamma 3%/3mm | 28.1 \\u00b1 12.6% | diagnostic | — |\n\n*Note: Metrics updated 2026-02-24 after switching inference default from overlap=32 to overlap=64 (see #50).*\n\n### 1.3 Conclusion\n\nThe v2.3 pipeline works end-to-end. Even a pure MSE baseline achieves surprisingly good PTV70 D95 accuracy (1.01 Gy mean error), but exhibits systematic PTV underdose (-0.86 Gy bias) and OAR Dmax hotspots — both patterns that the Phase 2 asymmetric PTV and DVH-aware losses are designed to address. A consistent Femur L > R asymmetry (7.2 Gy mean difference, 7/7 cases) warrants investigation. Case-level analysis reveals the model's main weakness is OAR dose prediction in cases with atypical dose spread (compact or unusually wide), where errors of 10-18 Gy per structure occur — expected to improve with more data and clinical losses."
  },
  {
   "cell_type": "markdown",
   "id": "cell-whatchanged",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. What Changed\n",
    "\n",
    "This is the **first experiment on v2.3 data**. There is no direct prior experiment to compare against on this data. The closest reference is the pilot `baseline_unet_run1` on v2.2.0 data (23 cases, home machine), but those metrics are **invalid** due to the D95 preprocessing artifact (#4).\n",
    "\n",
    "| Parameter | Pilot (v2.2.0) | This Experiment (v2.3) |\n",
    "|-----------|---------------|------------------------|\n",
    "| Data version | v2.2.0 (D95 artifact) | **v2.3.0 (fixed)** |\n",
    "| Cases | 23 | **74** |\n",
    "| Machine | Home (Windows) | **Work (WSL2)** |\n",
    "| Architecture | BaselineUNet3D | BaselineUNet3D (identical) |\n",
    "| Loss | MSE + neg penalty | MSE + neg penalty (identical) |\n",
    "| Epochs | 200 | 200 (identical) |\n",
    "| Patch size | 128 | 128 (identical) |\n",
    "\n",
    "**Everything else is identical.** The only changes are data version, case count, and compute platform."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-repro-header",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-repro-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "PROJECT_ROOT = Path('..').resolve()\n",
    "\n",
    "REPRODUCIBILITY = {\n",
    "    'git_commit': '82bddc5e5cac8faaa3aa63b14686bdccbf6bba3b',\n",
    "    'git_message': 'fix: Patch sampling crash when volume Z equals patch_size',\n",
    "    'python_version': '3.12.12',\n",
    "    'pytorch_version': '2.10.0+cu126',\n",
    "    'pytorch_lightning_version': '2.6.1',\n",
    "    'cuda_version': '12.6',\n",
    "    'gpu': 'NVIDIA GeForce RTX 3090',\n",
    "    'random_seed': 42,\n",
    "    'experiment_date': '2026-02-23',\n",
    "    'platform': 'WSL2 Ubuntu 24.04 LTS',\n",
    "}\n",
    "\n",
    "print('Reproducibility Information:')\n",
    "for k, v in REPRODUCIBILITY.items():\n",
    "    print(f'  {k}: {v}')\n",
    "\n",
    "env_snapshot = PROJECT_ROOT / 'runs' / 'baseline_v23_environment_snapshot.txt'\n",
    "print(f'\\n  Environment snapshot: {env_snapshot} ({\"exists\" if env_snapshot.exists() else \"MISSING\"})')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-repro-cmd",
   "metadata": {},
   "source": "### Command to Reproduce\n\n```bash\n# 1. Checkout exact code\ngit checkout 82bddc5e\n\n# 2. Activate environment\nconda activate vmat-diffusion\n\n# 3. Train (seed 42)\npython scripts/train_baseline_unet.py \\\n    --data_dir ~/data/processed_npz \\\n    --exp_name baseline_v23_seed42 \\\n    --epochs 200 \\\n    --batch_size 2 \\\n    --seed 42\n\n# 4. Evaluate (overlap=64, fixed in #50)\npython scripts/inference_baseline_unet.py \\\n    --checkpoint runs/baseline_v23_seed42/checkpoints/best-epoch=172-val/mae_gy=6.047.ckpt \\\n    --input_dir ~/data/processed_npz \\\n    --output_dir predictions/baseline_v23_seed42_test \\\n    --compute_metrics --gamma_subsample 4 --overlap 64\n```"
  },
  {
   "cell_type": "markdown",
   "id": "cell-dataset-header",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-dataset-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "PROJECT_ROOT = Path('..').resolve()\n",
    "\n",
    "# Load test case IDs\n",
    "test_cases_path = PROJECT_ROOT / 'runs' / 'baseline_v23_seed42' / 'test_cases.json'\n",
    "with open(test_cases_path) as f:\n",
    "    test_info = json.load(f)\n",
    "\n",
    "DATASET = {\n",
    "    'preprocessing_version': 'v2.3.0',\n",
    "    'total_cases': 74,\n",
    "    'plan_types': '11 SIB (70/56 Gy) + 63 single-Rx (70 Gy only)',\n",
    "    'train_cases': 60,\n",
    "    'val_cases': 7,\n",
    "    'test_case_ids': test_info['test_cases'],\n",
    "    'split_seed': test_info['seed'],\n",
    "    'note': 'Split is per-seed (not locked). Production will use locked stratified split (#38).',\n",
    "}\n",
    "\n",
    "print(f'Preprocessing version: {DATASET[\"preprocessing_version\"]}')\n",
    "print(f'Total cases: {DATASET[\"total_cases\"]} ({DATASET[\"plan_types\"]})')\n",
    "print(f'Split (seed={DATASET[\"split_seed\"]}): {DATASET[\"train_cases\"]} train / {DATASET[\"val_cases\"]} val / {len(DATASET[\"test_case_ids\"])} test')\n",
    "print(f'Test case IDs: {DATASET[\"test_case_ids\"]}')\n",
    "print(f'\\nNote: {DATASET[\"note\"]}')\n",
    "print(f'\\nWARNING: Test set contains NO PTV56 structures (all single-Rx cases).')\n",
    "print(f'This limits the clinical relevance — production run must use SIB-only dataset.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-model-header",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. Model & Training Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-model-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "PROJECT_ROOT = Path('..').resolve()\n",
    "\n",
    "config_path = PROJECT_ROOT / 'runs' / 'baseline_v23_seed42' / 'training_config.json'\n",
    "with open(config_path) as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "print(f'Model: {config[\"model\"]}')\n",
    "print(f'Parameters: {config[\"model_params\"]:,}')\n",
    "print(f'Script version: {config[\"version\"]}')\n",
    "print(f'\\nHyperparameters:')\n",
    "for k, v in sorted(config['hparams'].items()):\n",
    "    print(f'  {k}: {v}')\n",
    "\n",
    "# Training summary\n",
    "summary_path = PROJECT_ROOT / 'runs' / 'baseline_v23_seed42' / 'training_summary.json'\n",
    "with open(summary_path) as f:\n",
    "    summary = json.load(f)\n",
    "\n",
    "print(f'\\nTraining Summary:')\n",
    "print(f'  Duration: {summary[\"total_time_hours\"]:.1f} hours')\n",
    "print(f'  Final epoch: {summary[\"final_metrics\"][\"epoch\"]}')\n",
    "print(f'  Best val MAE: {summary[\"best_val_mae_gy\"]:.3f} Gy (epoch 172)')\n",
    "print(f'  Final val MAE: {summary[\"final_metrics\"][\"val_mae_gy\"]:.3f} Gy')\n",
    "print(f'  Final val Gamma: {summary[\"final_metrics\"][\"val_gamma\"]:.1f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-results-header",
   "metadata": {},
   "source": "---\n\n## 6. Results\n\nFigures generated by `scripts/generate_baseline_v23_figures.py` and loaded below.  \nRepresentative case for single-case figures: **prostate70gy_0056** (below-median MAE = 3.30 Gy). Inference uses overlap=64 (default updated in #50).\n\n### 6.1 Training Curves"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-fig1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "display(Image(filename='../runs/baseline_v23/figures/fig1_training_curves.png', width=900))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-fig1-caption",
   "metadata": {},
   "source": [
    "**Caption:** Training and validation curves for baseline_v23 (seed 42, 200 epochs). (A) Training loss (blue) decreases steadily while validation loss (orange) plateaus after ~50 epochs, indicating significant overfitting (8.5x val/train ratio by epoch 150). (B) Validation MAE (solid blue) and Gamma pass rate (dashed green) on dual axes, with best checkpoint marked at epoch 172 (MAE = 6.05 Gy). Both metrics are noisy due to the small validation set (n=7).\n",
    "\n",
    "**Key observations:**\n",
    "- Significant overfitting: val/train loss ratio reaches 8.5-10x, consistent with 23.7M parameters trained on only 60 cases\n",
    "- Val MAE essentially flat after epoch 100 (trend slope = -0.004 Gy/epoch) — model has converged\n",
    "- High epoch-to-epoch variance in val metrics due to small val set (n=7)\n",
    "- Best checkpoint at epoch 172 may be a favorable fluctuation; typical late-epoch MAE is ~7.5 Gy\n",
    "- **Clinical implication:** More training data (from Institution B) is the primary lever for improvement, not more epochs or architecture changes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-fig2-header",
   "metadata": {},
   "source": [
    "### 6.2 Dose Colorwash (Representative Case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-fig2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "display(Image(filename='../runs/baseline_v23/figures/fig2_dose_colorwash.png', width=900))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-fig2-caption",
   "metadata": {},
   "source": "**Caption:** Predicted (top) vs ground truth (bottom) dose distribution overlaid on CT for prostate70gy_0056 (MAE = 3.30 Gy, below-median test case). Views: axial (left), coronal (center), sagittal (right) through PTV70 centroid. Dose displayed in Gy with 5 Gy threshold. The high-dose PTV region (red, ~70 Gy) is well-reproduced in both shape and magnitude. The intermediate dose region (20-50 Gy, green-yellow) shows broader predicted distribution vs ground truth.\n\n**Key observations:**\n- PTV70 coverage is visually excellent — the high-dose region matches closely\n- The predicted dose \"spray\" in the low-dose periphery appears broader than GT, consistent with the model averaging over multiple valid low-dose solutions\n- Dose gradients at the PTV boundary appear smoother in the prediction than GT, which may reflect the MSE loss averaging effect\n- Coronal view shows symmetric predicted dose distribution (L/R ratio = 1.054), confirming correct sliding window blending with overlap=64\n- **Clinical implication:** The model captures the essential dose distribution pattern; errors are primarily in clinically less constrained regions"
  },
  {
   "cell_type": "markdown",
   "id": "cell-fig3-header",
   "metadata": {},
   "source": [
    "### 6.3 Dose Difference Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-fig3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "display(Image(filename='../runs/baseline_v23/figures/fig3_dose_difference.png', width=900))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-fig3-caption",
   "metadata": {},
   "source": "**Caption:** Dose difference map (predicted minus ground truth, in Gy) for prostate70gy_0056. Blue regions indicate underdose, red indicates overdose. Diverging RdBu_r colormap centered at zero.\n\n**Key observations:**\n- Largest errors are in the low-to-intermediate dose transition zone, not in the PTV itself\n- Blue (underdose) patches visible at the periphery — the model underpredicts dose in the low-dose \"spray\" region\n- The PTV region itself shows minimal difference (near-zero), confirming good target coverage accuracy\n- **Clinical implication:** The error pattern is spatially coherent and concentrated where clinical constraints are weakest, consistent with the semi-multi-modal hypothesis — multiple valid dose distributions exist in these regions"
  },
  {
   "cell_type": "markdown",
   "id": "cell-fig4-header",
   "metadata": {},
   "source": [
    "### 6.4 DVH Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-fig4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "display(Image(filename='../runs/baseline_v23/figures/fig4_dvh_comparison.png', width=800))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-fig4-caption",
   "metadata": {},
   "source": "**Caption:** DVH curves for prostate70gy_0056: solid lines = ground truth, dashed = predicted. Structures shown: PTV70, Rectum, Bladder, Femur_L, Femur_R, Bowel.\n\n**Key observations:**\n- **PTV70:** Predicted DVH closely matches GT — the steep drop-off near 70 Gy is well-captured, confirming good D95/D98 accuracy for this case\n- **Rectum:** Predicted DVH (dashed orange) shows higher dose across the mid-range compared to GT (solid orange), indicating the model overestimates rectum dose. This is the structure where Dmax violations occur\n- **Bladder:** Similar pattern — predicted DVH shifted slightly higher than GT in the mid-dose range\n- **Femur_L vs Femur_R:** Clear asymmetry — Femur_L predicted DVH diverges more from GT than Femur_R, consistent with the systematic L/R bias seen in all test cases\n- **Bowel:** Good agreement at low doses; prediction slightly overestimates\n- **Clinical implication:** OAR dose is systematically overestimated in predictions. While this is \"safe\" (conservative), it means the model predicts less OAR sparing than actually achieved, which could trigger false QUANTEC violations"
  },
  {
   "cell_type": "markdown",
   "id": "cell-fig5-header",
   "metadata": {},
   "source": [
    "### 6.5 Gamma Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-fig5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "display(Image(filename='../runs/baseline_v23/figures/fig5_gamma_bar_chart.png', width=900))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-fig5-caption",
   "metadata": {},
   "source": [
    "**Caption:** Global vs PTV-region gamma pass rate (3%/3mm) per test case. Blue bars: global gamma; gold bars: PTV-region gamma (PTV70 + 5mm margin). Dashed orange line: 95% clinical target.\n",
    "\n",
    "**Key observations:**\n",
    "- **PTV-region Gamma (85.5% mean) dramatically outperforms Global Gamma (27.7% mean)** — a 3x ratio, confirming the strategic decision to focus on PTV-region accuracy over global metrics\n",
    "- Two cases (P0005, P0024) achieve PTV-region Gamma near/above 95% — the model CAN reach clinical targets in the PTV\n",
    "- P0079 is an outlier with only 60.9% PTV Gamma — warrants case-level investigation\n",
    "- Global Gamma is dominated by failures in the low-dose periphery, as expected\n",
    "- **Clinical implication:** The model is clinically accurate where it matters most (PTV region). Global gamma reflects valid dose diversity in unconstrained regions, not model failure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-fig6-header",
   "metadata": {},
   "source": [
    "### 6.6 Per-Case Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-fig6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "display(Image(filename='../runs/baseline_v23/figures/fig6_per_case_boxplots.png', width=900))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-fig6-caption",
   "metadata": {},
   "source": "**Caption:** Distribution of key metrics across 7 test cases (seed 42). (A) MAE in Gy, (B) Global Gamma 3%/3mm pass rate, (C) PTV-region Gamma 3%/3mm, (D) PTV70 D95 error (predicted minus GT, negative = underdose). Individual data points shown as colored dots; box shows IQR.\n\n**Key observations:**\n- **MAE (4.80 +/- 2.45 Gy):** Wide spread from 1.5 to 9.3 Gy; two outlier cases (0005, 0065) have large OAR errors that dominate\n- **Global Gamma (28.1 +/- 12.6%):** Consistently low across all cases, confirming this is not an outlier effect\n- **PTV Gamma (85.5 +/- 10.9%):** Most cases clustered 83-96%, with P0079 as a clear outlier at 61%\n- **D95 Error (-0.86 +/- 0.92 Gy):** Systematic negative bias (underdose) — 5/7 cases show underdose. This is exactly the pattern the asymmetric PTV loss targets\n- **Clinical implication:** The D95 underdose bias is the most actionable finding — it's systematic, clinically relevant, and directly addressable with loss function engineering. The wide MAE spread reflects OAR dose prediction failures in atypical cases, addressable with more data and structure-aware losses"
  },
  {
   "cell_type": "markdown",
   "id": "cell-fig7-header",
   "metadata": {},
   "source": [
    "### 6.7 QUANTEC Compliance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-fig7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "display(Image(filename='../runs/baseline_v23/figures/fig7_quantec_compliance.png', width=900))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-fig7-caption",
   "metadata": {},
   "source": [
    "**Caption:** QUANTEC constraint compliance heatmap for 7 test cases. Green (P) = pass, orange (F) = fail. Rows: test cases; columns: individual clinical constraints.\n",
    "\n",
    "**Key observations:**\n",
    "- **4/7 cases pass all constraints (57% full compliance)**\n",
    "- All failures are **Dmax violations** (single-voxel hotspots): Rectum Dmax (P0027: 75.8 Gy, P0056: 75.1 Gy), Bladder Dmax (P0065: 75.8 Gy), Bowel Dmax (P0065: 55.5 Gy)\n",
    "- **Volume-based constraints (V70, V60, V50, V45) pass in ALL cases** — the model correctly predicts OAR DVH shapes\n",
    "- PTV70 D95 and V95 pass in ALL cases — the model meets PTV coverage requirements\n",
    "- **Clinical implication:** The Dmax violations are marginal (0.1-3.5 Gy over limit) and represent single-voxel artifacts, not systematic DVH failure. These could be addressed by Dmax-aware loss terms or post-processing. The volume constraint compliance is excellent and clinically meaningful"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-fig8-header",
   "metadata": {},
   "source": [
    "### 6.8 Femur L/R Asymmetry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-fig8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "display(Image(filename='../runs/baseline_v23/figures/fig8_femur_asymmetry.png', width=900))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-fig8-caption",
   "metadata": {},
   "source": [
    "**Caption:** Femur L/R dose prediction asymmetry analysis. (A) Paired MAE bars for Femur_L (green) vs Femur_R (blue) per case. (B) MAE difference (L minus R) showing consistent positive bias. Mean difference: 7.19 Gy. Femur_L is worse in 7/7 cases.\n",
    "\n",
    "**Key observations:**\n",
    "- **Femur_L MAE is 1.4-4.3x higher than Femur_R in every single test case** — this is 100% consistent, not a sampling artifact\n",
    "- Mean Femur_L MAE: 11.8 Gy vs Femur_R: 4.6 Gy (mean difference: 7.2 Gy)\n",
    "- The asymmetry is too consistent to be random — likely reflects a systematic bias in the training data\n",
    "- **Possible causes:** (1) Beam arrangement asymmetry in treatment plans (e.g., preferential beam angles that deliver more dose through left femur), (2) Patient positioning/anatomy laterality in the dataset, (3) L/R label confusion in some source contours\n",
    "- **Clinical implication:** This finding should be investigated before the production run. If it persists with more data, it may indicate a real dosimetric pattern in VMAT prostate plans. If it's a data issue (label swap), fixing it would immediately improve model accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-stats-header",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 7. Statistical Analysis\n",
    "\n",
    "**Status: PENDING** — requires seeds 123 and 456 to complete. Statistical analysis with n=7 cases from a single seed cannot support formal inference.\n",
    "\n",
    "When all 3 seeds are complete, this section will include:\n",
    "- Per-condition summary: mean +/- std across 3 seeds (averaged per-case first), with 95% bootstrap CI\n",
    "- Comparison to subsequent experiments via paired Wilcoxon signed-rank test\n",
    "\n",
    "### Preliminary Descriptive Statistics (Seed 42 Only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-stats-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "PROJECT_ROOT = Path('..').resolve()\n",
    "results_path = PROJECT_ROOT / 'predictions' / 'baseline_v23_seed42_test' / 'baseline_evaluation_results.json'\n",
    "\n",
    "with open(results_path) as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Extract metrics\n",
    "cases = data['per_case_results']\n",
    "maes = [c['dose_metrics']['mae_gy'] for c in cases]\n",
    "gammas_g = [c['gamma']['global_3mm3pct']['gamma_pass_rate'] for c in cases]\n",
    "gammas_p = [c['gamma']['ptv_region_3mm3pct']['gamma_pass_rate'] for c in cases]\n",
    "d95_errors = [c['dvh_metrics']['PTV70']['D95_error'] for c in cases if c['dvh_metrics'].get('PTV70', {}).get('D95_error') is not None]\n",
    "\n",
    "print('Descriptive Statistics (n=7, seed 42 only — NOT for formal inference)')\n",
    "print('='*65)\n",
    "print(f'{\"Metric\":<30} {\"Mean\":>8} {\"Std\":>8} {\"Min\":>8} {\"Max\":>8}')\n",
    "print('-'*65)\n",
    "for name, vals in [('MAE (Gy)', maes), ('Global Gamma (%)', gammas_g),\n",
    "                    ('PTV Gamma (%)', gammas_p), ('D95 Error (Gy)', d95_errors)]:\n",
    "    print(f'{name:<30} {np.mean(vals):>8.2f} {np.std(vals):>8.2f} {np.min(vals):>8.2f} {np.max(vals):>8.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-comparison-header",
   "metadata": {},
   "source": "---\n\n## 8. Cross-Experiment Comparison\n\n**Status: PENDING** — this is the first v2.3 experiment. No valid prior results exist for comparison (pilot metrics are invalid due to D95 artifact).\n\n| Experiment | Data | MAE (Gy) | Global Gamma | PTV Gamma | D95 \\|Error\\| | QUANTEC |\n|------------|------|----------|-------------|-----------|-------------|------|\n| **baseline_v23** (seed 42) | v2.3, 74 cases | 4.80 +/- 2.45 | 28.1 +/- 12.6% | 85.5 +/- 10.9% | 1.01 +/- 0.76 Gy | 57% |\n| pilot baseline (INVALID) | v2.2, 23 cases | ~~1.43~~ | ~~14.2%~~ | — | ~~-20 Gy~~ | — |\n\n*Note: MAE/Gamma updated 2026-02-24 with overlap=64 inference (#50). PTV Gamma, D95, and QUANTEC unchanged (PTV-region metrics are insensitive to overlap).*\n\nThe pilot numbers are struck through because they were computed on data with the D95 preprocessing artifact (#4) and cannot be meaningfully compared.\n\nThis table will expand as Phase 2 experiments are completed."
  },
  {
   "cell_type": "markdown",
   "id": "cell-conclusions",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 9. Conclusions, Limitations, and Next Steps\n",
    "\n",
    "### Conclusions\n",
    "\n",
    "1. **Pipeline validated end-to-end** — v2.3 preprocessing, training, inference, and evaluation all work correctly on the work machine. This was the primary goal of this experiment.\n",
    "2. **D95 preprocessing fix confirmed** — all 7 GT D95 values >= 66.5 Gy (min = 68.7 Gy), confirming issue #4 is resolved.\n",
    "3. **PTV70 D95 accuracy is surprisingly good for a pure MSE baseline** — mean |error| of 1.01 Gy is within the pre-registered 2 Gy clinical threshold in 6/7 cases.\n",
    "4. **Systematic PTV underdose (-0.86 Gy bias) validates the Phase 2 strategy** — the asymmetric PTV loss is designed to penalize exactly this pattern.\n",
    "5. **QUANTEC violations are exclusively Dmax hotspots** — all volume constraints pass, indicating the model learns good DVH shapes but has single-voxel noise at high doses.\n",
    "6. **Femur L/R asymmetry is a new finding** — 7.2 Gy mean difference, consistent across 100% of test cases. Requires investigation.\n",
    "7. **Significant overfitting (8.5x val/train ratio)** — more data is the primary lever for improvement.\n",
    "\n",
    "### Limitations\n",
    "\n",
    "- **Single seed** — no measure of training variability. Seeds 123/456 are required for publishable results.\n",
    "- **Small test set (n=7)** — wide confidence intervals; individual cases dominate summary statistics.\n",
    "- **Mixed SIB + single-Rx dataset** — 63/74 cases are single-Rx (no PTV56). The model is primarily learning single-Rx dose patterns, which may not transfer to the SIB-only production dataset.\n",
    "- **No PTV56 in test set** — cannot evaluate the SIB dose-painting accuracy that is central to the paper.\n",
    "- **Per-seed data split** — test cases differ across seeds (locked stratified split #38 not yet implemented).\n",
    "- **Gamma subsample=4** — faster but lower resolution than publication-quality subsample=2.\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "- [ ] Investigate Femur L/R asymmetry: check training data for L/R label consistency, beam arrangement patterns\n",
    "- [ ] **Decision:** Run seeds 123/456 on this mixed dataset, or wait for SIB-only production data?\n",
    "- [ ] Collect Institution B data (#2) — this is the primary blocker for the production experiment\n",
    "- [ ] Define and implement locked stratified test set (#38)\n",
    "- [ ] When production data is ready: re-run baseline as Condition 1 of the Phase 2 ablation study"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-artifacts",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 10. Artifacts\n",
    "\n",
    "| Artifact | Path |\n",
    "|----------|------|\n",
    "| Best Checkpoint | `runs/baseline_v23_seed42/checkpoints/best-epoch=172-val/mae_gy=6.047.ckpt` |\n",
    "| Last Checkpoint | `runs/baseline_v23_seed42/checkpoints/last.ckpt` |\n",
    "| Training Metrics | `runs/baseline_v23_seed42/version_1/metrics.csv` |\n",
    "| Training Config | `runs/baseline_v23_seed42/training_config.json` |\n",
    "| Training Summary | `runs/baseline_v23_seed42/training_summary.json` |\n",
    "| Test Cases | `runs/baseline_v23_seed42/test_cases.json` |\n",
    "| Environment Snapshot | `runs/baseline_v23_environment_snapshot.txt` |\n",
    "| Run Log | `runs/baseline_v23_run.log` |\n",
    "| Figures (PNG + PDF) | `runs/baseline_v23/figures/` (8 figures, 16 files) |\n",
    "| Figure Generation Script | `scripts/generate_baseline_v23_figures.py` |\n",
    "| Test Predictions | `predictions/baseline_v23_seed42_test/*.npz` |\n",
    "| Evaluation Results | `predictions/baseline_v23_seed42_test/baseline_evaluation_results.json` |\n",
    "\n",
    "---\n",
    "\n",
    "*Notebook created: 2026-02-24*  \n",
    "*Last updated: 2026-02-24*  \n",
    "*Status: Preliminary (seed 42 only)*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}