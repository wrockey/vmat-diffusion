{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VMAT Dose Prediction: Results Analysis\n",
    "\n",
    "Post-training analysis notebook for evaluating model performance, comparing models, and generating publication-ready figures.\n",
    "\n",
    "**Usage:** Run after training and inference are complete."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from pathlib import Path\n",
    "import json\n",
    "from typing import Dict, List, Optional, Tuple\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configure for publication-quality figures\n",
    "plt.rcParams.update({\n",
    "    'font.size': 12,\n",
    "    'font.family': 'sans-serif',\n",
    "    'axes.labelsize': 12,\n",
    "    'axes.titlesize': 14,\n",
    "    'xtick.labelsize': 10,\n",
    "    'ytick.labelsize': 10,\n",
    "    'legend.fontsize': 10,\n",
    "    'figure.dpi': 150,\n",
    "    'savefig.dpi': 300,\n",
    "    'savefig.bbox': 'tight',\n",
    "})\n",
    "\n",
    "# Color scheme\n",
    "COLORS = {\n",
    "    'gt': '#2E86AB',      # Blue - ground truth\n",
    "    'pred': '#E94F37',    # Red - prediction\n",
    "    'diff': '#7B2D8E',    # Purple - difference\n",
    "    'pass': '#4CAF50',    # Green - pass\n",
    "    'fail': '#F44336',    # Red - fail\n",
    "}\n",
    "\n",
    "print(\"Setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Configuration\n",
    "\n",
    "**Edit these paths to match your setup:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# EDIT THESE PATHS\n",
    "# ============================================================================\n",
    "\n",
    "# Directories\n",
    "TEST_DATA_DIR = Path(\"./test_npz\")           # Ground truth test cases\n",
    "DDPM_PRED_DIR = Path(\"./predictions/ddpm\")   # Diffusion predictions\n",
    "BASELINE_PRED_DIR = Path(\"./predictions/baseline\")  # Baseline predictions\n",
    "\n",
    "# Results files\n",
    "DDPM_RESULTS = DDPM_PRED_DIR / \"evaluation_results.json\"\n",
    "BASELINE_RESULTS = BASELINE_PRED_DIR / \"baseline_evaluation_results.json\"\n",
    "\n",
    "# Output directory for figures\n",
    "FIGURES_DIR = Path(\"./figures\")\n",
    "FIGURES_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "# Prescription dose\n",
    "RX_DOSE_GY = 70.0\n",
    "\n",
    "# ============================================================================\n",
    "\n",
    "# Verify paths exist\n",
    "print(\"Checking paths...\")\n",
    "for p in [TEST_DATA_DIR, DDPM_PRED_DIR]:\n",
    "    status = \"✓\" if p.exists() else \"✗ NOT FOUND\"\n",
    "    print(f\"  {p}: {status}\")\n",
    "\n",
    "for p in [DDPM_RESULTS, BASELINE_RESULTS]:\n",
    "    status = \"✓\" if p.exists() else \"⚠ Not found (optional)\"\n",
    "    print(f\"  {p}: {status}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_results(results_path: Path) -> Optional[Dict]:\n",
    "    \"\"\"Load evaluation results JSON.\"\"\"\n",
    "    if not results_path.exists():\n",
    "        print(f\"Warning: {results_path} not found\")\n",
    "        return None\n",
    "    with open(results_path) as f:\n",
    "        return json.load(f)\n",
    "\n",
    "# Load results\n",
    "ddpm_results = load_results(DDPM_RESULTS)\n",
    "baseline_results = load_results(BASELINE_RESULTS)\n",
    "\n",
    "# Summary\n",
    "if ddpm_results:\n",
    "    print(f\"\\nDDPM Results: {ddpm_results['n_cases']} cases\")\n",
    "    print(f\"  MAE: {ddpm_results['aggregate_metrics']['mae_gy_mean']:.2f} ± {ddpm_results['aggregate_metrics']['mae_gy_std']:.2f} Gy\")\n",
    "    if 'gamma_pass_rate_mean' in ddpm_results['aggregate_metrics']:\n",
    "        print(f\"  Gamma: {ddpm_results['aggregate_metrics']['gamma_pass_rate_mean']:.1f} ± {ddpm_results['aggregate_metrics']['gamma_pass_rate_std']:.1f}%\")\n",
    "\n",
    "if baseline_results:\n",
    "    print(f\"\\nBaseline Results: {baseline_results['n_cases']} cases\")\n",
    "    print(f\"  MAE: {baseline_results['aggregate_metrics']['mae_gy_mean']:.2f} ± {baseline_results['aggregate_metrics']['mae_gy_std']:.2f} Gy\")\n",
    "    if 'gamma_pass_rate_mean' in baseline_results['aggregate_metrics']:\n",
    "        print(f\"  Gamma: {baseline_results['aggregate_metrics']['gamma_pass_rate_mean']:.1f} ± {baseline_results['aggregate_metrics']['gamma_pass_rate_std']:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model Comparison Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_comparison_table(ddpm: Dict, baseline: Dict) -> None:\n",
    "    \"\"\"Print formatted comparison table.\"\"\"\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"MODEL COMPARISON\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"{'Metric':<30} {'DDPM':<18} {'Baseline':<18}\")\n",
    "    print(\"-\"*70)\n",
    "    \n",
    "    # MAE\n",
    "    ddpm_mae = f\"{ddpm['aggregate_metrics']['mae_gy_mean']:.2f} ± {ddpm['aggregate_metrics']['mae_gy_std']:.2f}\"\n",
    "    base_mae = f\"{baseline['aggregate_metrics']['mae_gy_mean']:.2f} ± {baseline['aggregate_metrics']['mae_gy_std']:.2f}\"\n",
    "    winner = \"←\" if ddpm['aggregate_metrics']['mae_gy_mean'] < baseline['aggregate_metrics']['mae_gy_mean'] else \"→\"\n",
    "    print(f\"{'MAE (Gy)':<30} {ddpm_mae:<18} {base_mae:<18} {winner}\")\n",
    "    \n",
    "    # Gamma\n",
    "    if 'gamma_pass_rate_mean' in ddpm['aggregate_metrics']:\n",
    "        ddpm_gamma = f\"{ddpm['aggregate_metrics']['gamma_pass_rate_mean']:.1f} ± {ddpm['aggregate_metrics']['gamma_pass_rate_std']:.1f}\"\n",
    "        base_gamma = f\"{baseline['aggregate_metrics']['gamma_pass_rate_mean']:.1f} ± {baseline['aggregate_metrics']['gamma_pass_rate_std']:.1f}\"\n",
    "        winner = \"←\" if ddpm['aggregate_metrics']['gamma_pass_rate_mean'] > baseline['aggregate_metrics']['gamma_pass_rate_mean'] else \"→\"\n",
    "        print(f\"{'Gamma 3%/3mm (%)':<30} {ddpm_gamma:<18} {base_gamma:<18} {winner}\")\n",
    "    \n",
    "    # Clinical constraints\n",
    "    if 'clinical_constraints' in ddpm:\n",
    "        ddpm_pass = f\"{ddpm['clinical_constraints']['cases_all_passed']}/{ddpm['n_cases']}\"\n",
    "        base_pass = f\"{baseline['clinical_constraints']['cases_all_passed']}/{baseline['n_cases']}\"\n",
    "        print(f\"{'Cases passing all constraints':<30} {ddpm_pass:<18} {base_pass:<18}\")\n",
    "    \n",
    "    print(\"-\"*70)\n",
    "    print(\"← = DDPM better, → = Baseline better\")\n",
    "    print(\"=\"*70)\n",
    "\n",
    "if ddpm_results and baseline_results:\n",
    "    create_comparison_table(ddpm_results, baseline_results)\n",
    "else:\n",
    "    print(\"Need both DDPM and baseline results for comparison\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Per-Case Metrics Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_per_case_metrics(ddpm: Dict, baseline: Dict = None) -> plt.Figure:\n",
    "    \"\"\"Bar chart comparing per-case MAE and Gamma.\"\"\"\n",
    "    \n",
    "    # Extract per-case data\n",
    "    cases = [r['case_id'] for r in ddpm['per_case_results']]\n",
    "    ddpm_mae = [r['dose_metrics']['mae_gy'] for r in ddpm['per_case_results']]\n",
    "    ddpm_gamma = [r['gamma']['gamma_pass_rate'] for r in ddpm['per_case_results'] \n",
    "                  if 'gamma' in r and r['gamma'].get('gamma_pass_rate')]\n",
    "    \n",
    "    if baseline:\n",
    "        base_mae = [r['dose_metrics']['mae_gy'] for r in baseline['per_case_results']]\n",
    "        base_gamma = [r['gamma']['gamma_pass_rate'] for r in baseline['per_case_results']\n",
    "                     if 'gamma' in r and r['gamma'].get('gamma_pass_rate')]\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    x = np.arange(len(cases))\n",
    "    width = 0.35\n",
    "    \n",
    "    # MAE plot\n",
    "    ax = axes[0]\n",
    "    bars1 = ax.bar(x - width/2, ddpm_mae, width, label='DDPM', color=COLORS['gt'])\n",
    "    if baseline:\n",
    "        bars2 = ax.bar(x + width/2, base_mae, width, label='Baseline', color=COLORS['pred'])\n",
    "    ax.axhline(y=2.0, color='green', linestyle='--', label='Target (< 2 Gy)')\n",
    "    ax.set_xlabel('Case')\n",
    "    ax.set_ylabel('MAE (Gy)')\n",
    "    ax.set_title('Mean Absolute Error by Case')\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(cases, rotation=45, ha='right')\n",
    "    ax.legend()\n",
    "    ax.set_ylim(0, max(ddpm_mae + (base_mae if baseline else [])) * 1.2)\n",
    "    \n",
    "    # Gamma plot\n",
    "    ax = axes[1]\n",
    "    if ddpm_gamma:\n",
    "        bars1 = ax.bar(x - width/2, ddpm_gamma, width, label='DDPM', color=COLORS['gt'])\n",
    "        if baseline and base_gamma:\n",
    "            bars2 = ax.bar(x + width/2, base_gamma, width, label='Baseline', color=COLORS['pred'])\n",
    "        ax.axhline(y=95.0, color='green', linestyle='--', label='Target (> 95%)')\n",
    "        ax.set_xlabel('Case')\n",
    "        ax.set_ylabel('Gamma Pass Rate (%)')\n",
    "        ax.set_title('Gamma (3%/3mm) by Case')\n",
    "        ax.set_xticks(x)\n",
    "        ax.set_xticklabels(cases, rotation=45, ha='right')\n",
    "        ax.legend()\n",
    "        ax.set_ylim(0, 105)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "if ddpm_results:\n",
    "    fig = plot_per_case_metrics(ddpm_results, baseline_results)\n",
    "    fig.savefig(FIGURES_DIR / 'per_case_metrics.png')\n",
    "    plt.show()\n",
    "    print(f\"Saved: {FIGURES_DIR / 'per_case_metrics.png'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Load Case Data for Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_case_data(case_id: str) -> Dict:\n",
    "    \"\"\"Load ground truth, predictions, and masks for a case.\"\"\"\n",
    "    \n",
    "    # Find ground truth\n",
    "    gt_path = TEST_DATA_DIR / f\"{case_id}.npz\"\n",
    "    if not gt_path.exists():\n",
    "        raise FileNotFoundError(f\"Ground truth not found: {gt_path}\")\n",
    "    \n",
    "    gt_data = np.load(gt_path, allow_pickle=True)\n",
    "    \n",
    "    result = {\n",
    "        'case_id': case_id,\n",
    "        'ct': gt_data['ct'],\n",
    "        'gt_dose': gt_data['dose'],\n",
    "        'masks': gt_data['masks'],\n",
    "        'masks_sdf': gt_data['masks_sdf'] if 'masks_sdf' in gt_data.files else None,\n",
    "    }\n",
    "    \n",
    "    # Load DDPM prediction\n",
    "    ddpm_path = DDPM_PRED_DIR / f\"{case_id}_pred.npz\"\n",
    "    if ddpm_path.exists():\n",
    "        ddpm_data = np.load(ddpm_path)\n",
    "        result['ddpm_dose'] = ddpm_data['dose']\n",
    "    \n",
    "    # Load baseline prediction\n",
    "    baseline_path = BASELINE_PRED_DIR / f\"{case_id}_pred.npz\"\n",
    "    if baseline_path.exists():\n",
    "        baseline_data = np.load(baseline_path)\n",
    "        result['baseline_dose'] = baseline_data['dose']\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Get list of test cases\n",
    "test_cases = [f.stem for f in TEST_DATA_DIR.glob(\"*.npz\")] if TEST_DATA_DIR.exists() else []\n",
    "print(f\"Found {len(test_cases)} test cases: {test_cases}\")\n",
    "\n",
    "# Load first case for visualization\n",
    "if test_cases:\n",
    "    case_data = load_case_data(test_cases[0])\n",
    "    print(f\"\\nLoaded case: {case_data['case_id']}\")\n",
    "    print(f\"  CT shape: {case_data['ct'].shape}\")\n",
    "    print(f\"  GT dose shape: {case_data['gt_dose'].shape}\")\n",
    "    if 'ddpm_dose' in case_data:\n",
    "        print(f\"  DDPM prediction: loaded\")\n",
    "    if 'baseline_dose' in case_data:\n",
    "        print(f\"  Baseline prediction: loaded\")\n",
    "else:\n",
    "    print(\"No test cases found. Check TEST_DATA_DIR path.\")\n",
    "    case_data = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Dose Distribution Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_dose_comparison(\n",
    "    case_data: Dict,\n",
    "    slice_idx: int = None,\n",
    "    view: str = 'axial',  # 'axial', 'sagittal', 'coronal'\n",
    "    model: str = 'ddpm',  # 'ddpm' or 'baseline'\n",
    ") -> plt.Figure:\n",
    "    \"\"\"\n",
    "    Plot ground truth, prediction, and difference maps.\n",
    "    \"\"\"\n",
    "    gt_dose = case_data['gt_dose'] * RX_DOSE_GY\n",
    "    pred_key = f'{model}_dose'\n",
    "    \n",
    "    if pred_key not in case_data:\n",
    "        raise ValueError(f\"No {model} prediction available\")\n",
    "    \n",
    "    pred_dose = case_data[pred_key] * RX_DOSE_GY\n",
    "    diff = pred_dose - gt_dose\n",
    "    \n",
    "    # Get slice\n",
    "    if view == 'axial':\n",
    "        idx = slice_idx or gt_dose.shape[2] // 2\n",
    "        gt_slice = gt_dose[:, :, idx]\n",
    "        pred_slice = pred_dose[:, :, idx]\n",
    "        diff_slice = diff[:, :, idx]\n",
    "        ct_slice = case_data['ct'][:, :, idx]\n",
    "    elif view == 'sagittal':\n",
    "        idx = slice_idx or gt_dose.shape[0] // 2\n",
    "        gt_slice = gt_dose[idx, :, :]\n",
    "        pred_slice = pred_dose[idx, :, :]\n",
    "        diff_slice = diff[idx, :, :]\n",
    "        ct_slice = case_data['ct'][idx, :, :]\n",
    "    else:  # coronal\n",
    "        idx = slice_idx or gt_dose.shape[1] // 2\n",
    "        gt_slice = gt_dose[:, idx, :]\n",
    "        pred_slice = pred_dose[:, idx, :]\n",
    "        diff_slice = diff[:, idx, :]\n",
    "        ct_slice = case_data['ct'][:, idx, :]\n",
    "    \n",
    "    # Create figure\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "    \n",
    "    # Row 1: CT + Dose overlays\n",
    "    dose_vmax = max(gt_slice.max(), pred_slice.max())\n",
    "    \n",
    "    # GT\n",
    "    axes[0, 0].imshow(ct_slice, cmap='gray', aspect='auto')\n",
    "    im = axes[0, 0].imshow(gt_slice, cmap='jet', alpha=0.6, vmin=0, vmax=dose_vmax, aspect='auto')\n",
    "    axes[0, 0].set_title('Ground Truth Dose')\n",
    "    axes[0, 0].axis('off')\n",
    "    plt.colorbar(im, ax=axes[0, 0], label='Dose (Gy)', shrink=0.8)\n",
    "    \n",
    "    # Prediction\n",
    "    axes[0, 1].imshow(ct_slice, cmap='gray', aspect='auto')\n",
    "    im = axes[0, 1].imshow(pred_slice, cmap='jet', alpha=0.6, vmin=0, vmax=dose_vmax, aspect='auto')\n",
    "    axes[0, 1].set_title(f'Predicted Dose ({model.upper()})')\n",
    "    axes[0, 1].axis('off')\n",
    "    plt.colorbar(im, ax=axes[0, 1], label='Dose (Gy)', shrink=0.8)\n",
    "    \n",
    "    # Difference\n",
    "    diff_max = max(abs(diff_slice.min()), abs(diff_slice.max()), 5)\n",
    "    axes[0, 2].imshow(ct_slice, cmap='gray', aspect='auto')\n",
    "    im = axes[0, 2].imshow(diff_slice, cmap='RdBu_r', alpha=0.7, vmin=-diff_max, vmax=diff_max, aspect='auto')\n",
    "    axes[0, 2].set_title('Difference (Pred - GT)')\n",
    "    axes[0, 2].axis('off')\n",
    "    plt.colorbar(im, ax=axes[0, 2], label='Δ Dose (Gy)', shrink=0.8)\n",
    "    \n",
    "    # Row 2: Dose only (no CT background)\n",
    "    axes[1, 0].imshow(gt_slice, cmap='jet', vmin=0, vmax=dose_vmax, aspect='auto')\n",
    "    axes[1, 0].set_title('Ground Truth')\n",
    "    axes[1, 0].axis('off')\n",
    "    \n",
    "    axes[1, 1].imshow(pred_slice, cmap='jet', vmin=0, vmax=dose_vmax, aspect='auto')\n",
    "    axes[1, 1].set_title('Prediction')\n",
    "    axes[1, 1].axis('off')\n",
    "    \n",
    "    # Absolute error\n",
    "    abs_diff = np.abs(diff_slice)\n",
    "    im = axes[1, 2].imshow(abs_diff, cmap='hot', vmin=0, vmax=5, aspect='auto')\n",
    "    axes[1, 2].set_title('Absolute Error')\n",
    "    axes[1, 2].axis('off')\n",
    "    plt.colorbar(im, ax=axes[1, 2], label='|Error| (Gy)', shrink=0.8)\n",
    "    \n",
    "    fig.suptitle(f\"Case: {case_data['case_id']} | View: {view} | Slice: {idx}\", fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    return fig\n",
    "\n",
    "# Plot for first test case\n",
    "if case_data and 'ddpm_dose' in case_data:\n",
    "    fig = plot_dose_comparison(case_data, view='axial', model='ddpm')\n",
    "    fig.savefig(FIGURES_DIR / f\"{case_data['case_id']}_dose_comparison.png\")\n",
    "    plt.show()\n",
    "    print(f\"Saved: {FIGURES_DIR / f'{case_data[chr(39)+chr(39)+'case_id'+chr(39)+chr(39)]}_dose_comparison.png'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. DVH Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STRUCTURE_NAMES = {\n",
    "    0: 'PTV70',\n",
    "    1: 'PTV56',\n",
    "    2: 'Prostate',\n",
    "    3: 'Rectum',\n",
    "    4: 'Bladder',\n",
    "    5: 'Femur_L',\n",
    "    6: 'Femur_R',\n",
    "    7: 'Bowel',\n",
    "}\n",
    "\n",
    "STRUCTURE_COLORS = {\n",
    "    'PTV70': '#E41A1C',\n",
    "    'PTV56': '#FF7F00',\n",
    "    'Prostate': '#984EA3',\n",
    "    'Rectum': '#4DAF4A',\n",
    "    'Bladder': '#377EB8',\n",
    "    'Femur_L': '#A65628',\n",
    "    'Femur_R': '#F781BF',\n",
    "    'Bowel': '#999999',\n",
    "}\n",
    "\n",
    "def compute_dvh(dose: np.ndarray, mask: np.ndarray, bins: int = 200) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"Compute cumulative DVH.\"\"\"\n",
    "    dose_in_struct = dose[mask > 0]\n",
    "    if len(dose_in_struct) == 0:\n",
    "        return np.array([]), np.array([])\n",
    "    \n",
    "    max_dose = dose_in_struct.max()\n",
    "    hist, edges = np.histogram(dose_in_struct, bins=bins, range=(0, max_dose * 1.05))\n",
    "    cumulative = np.cumsum(hist[::-1])[::-1]\n",
    "    cumulative = cumulative / cumulative[0] * 100  # Normalize to %\n",
    "    \n",
    "    return edges[:-1], cumulative\n",
    "\n",
    "def plot_dvh_comparison(\n",
    "    case_data: Dict,\n",
    "    structures: List[str] = None,\n",
    "    model: str = 'ddpm',\n",
    ") -> plt.Figure:\n",
    "    \"\"\"Plot DVH comparison for ground truth vs prediction.\"\"\"\n",
    "    \n",
    "    gt_dose = case_data['gt_dose'] * RX_DOSE_GY\n",
    "    pred_dose = case_data[f'{model}_dose'] * RX_DOSE_GY\n",
    "    masks = case_data['masks']\n",
    "    \n",
    "    if structures is None:\n",
    "        structures = ['PTV70', 'Rectum', 'Bladder']\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10, 7))\n",
    "    \n",
    "    for struct_name in structures:\n",
    "        # Find structure index\n",
    "        struct_idx = None\n",
    "        for idx, name in STRUCTURE_NAMES.items():\n",
    "            if name == struct_name:\n",
    "                struct_idx = idx\n",
    "                break\n",
    "        \n",
    "        if struct_idx is None or struct_idx >= masks.shape[0]:\n",
    "            continue\n",
    "        \n",
    "        mask = masks[struct_idx]\n",
    "        if mask.sum() == 0:\n",
    "            continue\n",
    "        \n",
    "        color = STRUCTURE_COLORS.get(struct_name, 'gray')\n",
    "        \n",
    "        # Ground truth DVH\n",
    "        gt_x, gt_y = compute_dvh(gt_dose, mask)\n",
    "        if len(gt_x) > 0:\n",
    "            ax.plot(gt_x, gt_y, color=color, linestyle='-', linewidth=2, \n",
    "                   label=f'{struct_name} (GT)')\n",
    "        \n",
    "        # Predicted DVH\n",
    "        pred_x, pred_y = compute_dvh(pred_dose, mask)\n",
    "        if len(pred_x) > 0:\n",
    "            ax.plot(pred_x, pred_y, color=color, linestyle='--', linewidth=2,\n",
    "                   label=f'{struct_name} (Pred)')\n",
    "    \n",
    "    ax.set_xlabel('Dose (Gy)', fontsize=12)\n",
    "    ax.set_ylabel('Volume (%)', fontsize=12)\n",
    "    ax.set_title(f'DVH Comparison: {case_data[\"case_id\"]}', fontsize=14)\n",
    "    ax.set_xlim(0, 80)\n",
    "    ax.set_ylim(0, 105)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.legend(loc='upper right', ncol=2)\n",
    "    \n",
    "    # Add prescription lines\n",
    "    ax.axvline(x=70, color='red', linestyle=':', alpha=0.5)\n",
    "    ax.axvline(x=56, color='orange', linestyle=':', alpha=0.5)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "if case_data and 'ddpm_dose' in case_data:\n",
    "    fig = plot_dvh_comparison(case_data, structures=['PTV70', 'Rectum', 'Bladder'], model='ddpm')\n",
    "    fig.savefig(FIGURES_DIR / f\"{case_data['case_id']}_dvh.png\")\n",
    "    plt.show()\n",
    "    print(f\"Saved: {FIGURES_DIR / f'{case_data[chr(39)+chr(39)+'case_id'+chr(39)+chr(39)]}_dvh.png'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. DVH Metrics Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_dvh_metrics(dose: np.ndarray, mask: np.ndarray) -> Dict:\n",
    "    \"\"\"Compute DVH metrics for a structure.\"\"\"\n",
    "    dose_in_struct = dose[mask > 0]\n",
    "    if len(dose_in_struct) == 0:\n",
    "        return {}\n",
    "    \n",
    "    return {\n",
    "        'D95': np.percentile(dose_in_struct, 5),   # Dose to 95% of volume\n",
    "        'D50': np.percentile(dose_in_struct, 50),  # Dose to 50% of volume\n",
    "        'D5': np.percentile(dose_in_struct, 95),   # Dose to 5% of volume\n",
    "        'Dmax': dose_in_struct.max(),\n",
    "        'Dmean': dose_in_struct.mean(),\n",
    "        'V70': (dose_in_struct >= 70).sum() / len(dose_in_struct) * 100,\n",
    "        'V60': (dose_in_struct >= 60).sum() / len(dose_in_struct) * 100,\n",
    "        'V50': (dose_in_struct >= 50).sum() / len(dose_in_struct) * 100,\n",
    "    }\n",
    "\n",
    "def print_dvh_metrics_table(case_data: Dict, model: str = 'ddpm') -> None:\n",
    "    \"\"\"Print DVH metrics comparison table.\"\"\"\n",
    "    \n",
    "    gt_dose = case_data['gt_dose'] * RX_DOSE_GY\n",
    "    pred_dose = case_data[f'{model}_dose'] * RX_DOSE_GY\n",
    "    masks = case_data['masks']\n",
    "    \n",
    "    print(f\"\\nDVH Metrics: {case_data['case_id']} ({model.upper()})\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    for struct_idx, struct_name in STRUCTURE_NAMES.items():\n",
    "        if struct_idx >= masks.shape[0]:\n",
    "            continue\n",
    "        \n",
    "        mask = masks[struct_idx]\n",
    "        if mask.sum() == 0:\n",
    "            continue\n",
    "        \n",
    "        gt_metrics = compute_dvh_metrics(gt_dose, mask)\n",
    "        pred_metrics = compute_dvh_metrics(pred_dose, mask)\n",
    "        \n",
    "        print(f\"\\n{struct_name}:\")\n",
    "        print(f\"  {'Metric':<10} {'GT':>10} {'Pred':>10} {'Diff':>10}\")\n",
    "        print(f\"  {'-'*42}\")\n",
    "        \n",
    "        for key in ['D95', 'D50', 'Dmean', 'Dmax']:\n",
    "            gt_val = gt_metrics.get(key, 0)\n",
    "            pred_val = pred_metrics.get(key, 0)\n",
    "            diff = pred_val - gt_val\n",
    "            print(f\"  {key:<10} {gt_val:>10.2f} {pred_val:>10.2f} {diff:>+10.2f} Gy\")\n",
    "        \n",
    "        for key in ['V70', 'V60', 'V50']:\n",
    "            gt_val = gt_metrics.get(key, 0)\n",
    "            pred_val = pred_metrics.get(key, 0)\n",
    "            diff = pred_val - gt_val\n",
    "            print(f\"  {key:<10} {gt_val:>10.1f} {pred_val:>10.1f} {diff:>+10.1f} %\")\n",
    "\n",
    "if case_data and 'ddpm_dose' in case_data:\n",
    "    print_dvh_metrics_table(case_data, model='ddpm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Clinical Constraints Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_clinical_constraints(results: Dict) -> plt.Figure:\n",
    "    \"\"\"Visualize clinical constraint pass/fail across cases.\"\"\"\n",
    "    \n",
    "    if 'clinical_constraints' not in results:\n",
    "        print(\"No clinical constraints data available\")\n",
    "        return None\n",
    "    \n",
    "    # Extract violation data\n",
    "    cases = [r['case_id'] for r in results['per_case_results']]\n",
    "    violations_per_case = [\n",
    "        len(r.get('clinical_constraints', {}).get('violations', []))\n",
    "        for r in results['per_case_results']\n",
    "    ]\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    # Bar chart of violations per case\n",
    "    colors = [COLORS['pass'] if v == 0 else COLORS['fail'] for v in violations_per_case]\n",
    "    axes[0].bar(range(len(cases)), violations_per_case, color=colors)\n",
    "    axes[0].set_xticks(range(len(cases)))\n",
    "    axes[0].set_xticklabels(cases, rotation=45, ha='right')\n",
    "    axes[0].set_xlabel('Case')\n",
    "    axes[0].set_ylabel('Number of Violations')\n",
    "    axes[0].set_title('Clinical Constraint Violations by Case')\n",
    "    axes[0].axhline(y=0, color='green', linestyle='--', alpha=0.5)\n",
    "    \n",
    "    # Pie chart of overall pass/fail\n",
    "    cc = results['clinical_constraints']\n",
    "    passed = cc['cases_all_passed']\n",
    "    failed = results['n_cases'] - passed\n",
    "    \n",
    "    axes[1].pie(\n",
    "        [passed, failed],\n",
    "        labels=['Passed', 'Failed'],\n",
    "        colors=[COLORS['pass'], COLORS['fail']],\n",
    "        autopct='%1.0f%%',\n",
    "        startangle=90,\n",
    "        explode=(0.05, 0),\n",
    "    )\n",
    "    axes[1].set_title(f'Cases Meeting All Constraints\\n({passed}/{results[\"n_cases\"]})')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "if ddpm_results:\n",
    "    fig = plot_clinical_constraints(ddpm_results)\n",
    "    if fig:\n",
    "        fig.savefig(FIGURES_DIR / 'clinical_constraints.png')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_violation_summary(results: Dict) -> None:\n",
    "    \"\"\"Print summary of clinical constraint violations.\"\"\"\n",
    "    \n",
    "    if 'clinical_constraints' not in results:\n",
    "        print(\"No clinical constraints data available\")\n",
    "        return\n",
    "    \n",
    "    cc = results['clinical_constraints']\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"CLINICAL CONSTRAINTS SUMMARY\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Cases passing ALL constraints: {cc['cases_all_passed']}/{results['n_cases']}\")\n",
    "    print(f\"Total violations: {cc['total_violations']}\")\n",
    "    \n",
    "    if cc['violation_counts']:\n",
    "        print(\"\\nViolation breakdown:\")\n",
    "        for violation, count in sorted(cc['violation_counts'].items(), key=lambda x: -x[1]):\n",
    "            print(f\"  {violation}: {count} case(s)\")\n",
    "    else:\n",
    "        print(\"\\n✓ No violations!\")\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "\n",
    "if ddpm_results:\n",
    "    print_violation_summary(ddpm_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Error Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_error_histogram(case_data: Dict, model: str = 'ddpm') -> plt.Figure:\n",
    "    \"\"\"Plot histogram of dose errors.\"\"\"\n",
    "    \n",
    "    gt_dose = case_data['gt_dose'] * RX_DOSE_GY\n",
    "    pred_dose = case_data[f'{model}_dose'] * RX_DOSE_GY\n",
    "    \n",
    "    # Only consider voxels with significant dose\n",
    "    mask = gt_dose > 5  # >5 Gy\n",
    "    errors = (pred_dose[mask] - gt_dose[mask])\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "    \n",
    "    # Error histogram\n",
    "    axes[0].hist(errors, bins=100, color=COLORS['diff'], alpha=0.7, edgecolor='black')\n",
    "    axes[0].axvline(x=0, color='black', linestyle='-', linewidth=2)\n",
    "    axes[0].axvline(x=errors.mean(), color='red', linestyle='--', label=f'Mean: {errors.mean():.2f} Gy')\n",
    "    axes[0].set_xlabel('Error (Gy)')\n",
    "    axes[0].set_ylabel('Frequency')\n",
    "    axes[0].set_title(f'Dose Error Distribution (Dose > 5 Gy)\\nCase: {case_data[\"case_id\"]}')\n",
    "    axes[0].legend()\n",
    "    \n",
    "    # Statistics\n",
    "    stats_text = f\"\"\"\n",
    "    Statistics (Dose > 5 Gy region):\n",
    "    \n",
    "    Mean Error: {errors.mean():.3f} Gy\n",
    "    Std Error:  {errors.std():.3f} Gy\n",
    "    MAE:        {np.abs(errors).mean():.3f} Gy\n",
    "    \n",
    "    Percentiles:\n",
    "      5th:  {np.percentile(errors, 5):.2f} Gy\n",
    "      50th: {np.percentile(errors, 50):.2f} Gy\n",
    "      95th: {np.percentile(errors, 95):.2f} Gy\n",
    "    \n",
    "    Max Underdose: {errors.min():.2f} Gy\n",
    "    Max Overdose:  {errors.max():.2f} Gy\n",
    "    \"\"\"\n",
    "    \n",
    "    axes[1].text(0.1, 0.5, stats_text, transform=axes[1].transAxes,\n",
    "                fontsize=11, verticalalignment='center', fontfamily='monospace')\n",
    "    axes[1].axis('off')\n",
    "    axes[1].set_title('Error Statistics')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "if case_data and 'ddpm_dose' in case_data:\n",
    "    fig = plot_error_histogram(case_data, model='ddpm')\n",
    "    fig.savefig(FIGURES_DIR / f\"{case_data['case_id']}_error_histogram.png\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Publication Figure: Combined Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_publication_figure(case_data: Dict, model: str = 'ddpm') -> plt.Figure:\n",
    "    \"\"\"Create a publication-ready combined figure.\"\"\"\n",
    "    \n",
    "    gt_dose = case_data['gt_dose'] * RX_DOSE_GY\n",
    "    pred_dose = case_data[f'{model}_dose'] * RX_DOSE_GY\n",
    "    diff = pred_dose - gt_dose\n",
    "    masks = case_data['masks']\n",
    "    ct = case_data['ct']\n",
    "    \n",
    "    # Get mid-slices\n",
    "    z_mid = gt_dose.shape[2] // 2\n",
    "    \n",
    "    fig = plt.figure(figsize=(16, 10))\n",
    "    gs = gridspec.GridSpec(2, 4, figure=fig, wspace=0.3, hspace=0.3)\n",
    "    \n",
    "    dose_vmax = max(gt_dose[:,:,z_mid].max(), pred_dose[:,:,z_mid].max())\n",
    "    \n",
    "    # Row 1: CT, GT Dose, Pred Dose, Difference\n",
    "    ax1 = fig.add_subplot(gs[0, 0])\n",
    "    ax1.imshow(ct[:,:,z_mid], cmap='gray')\n",
    "    ax1.set_title('CT')\n",
    "    ax1.axis('off')\n",
    "    \n",
    "    ax2 = fig.add_subplot(gs[0, 1])\n",
    "    im2 = ax2.imshow(gt_dose[:,:,z_mid], cmap='jet', vmin=0, vmax=dose_vmax)\n",
    "    ax2.set_title('Ground Truth')\n",
    "    ax2.axis('off')\n",
    "    plt.colorbar(im2, ax=ax2, label='Gy', shrink=0.8)\n",
    "    \n",
    "    ax3 = fig.add_subplot(gs[0, 2])\n",
    "    im3 = ax3.imshow(pred_dose[:,:,z_mid], cmap='jet', vmin=0, vmax=dose_vmax)\n",
    "    ax3.set_title('Prediction')\n",
    "    ax3.axis('off')\n",
    "    plt.colorbar(im3, ax=ax3, label='Gy', shrink=0.8)\n",
    "    \n",
    "    ax4 = fig.add_subplot(gs[0, 3])\n",
    "    im4 = ax4.imshow(diff[:,:,z_mid], cmap='RdBu_r', vmin=-5, vmax=5)\n",
    "    ax4.set_title('Difference')\n",
    "    ax4.axis('off')\n",
    "    plt.colorbar(im4, ax=ax4, label='Gy', shrink=0.8)\n",
    "    \n",
    "    # Row 2: DVH and Statistics\n",
    "    ax5 = fig.add_subplot(gs[1, :2])\n",
    "    \n",
    "    for struct_name in ['PTV70', 'Rectum', 'Bladder']:\n",
    "        struct_idx = None\n",
    "        for idx, name in STRUCTURE_NAMES.items():\n",
    "            if name == struct_name:\n",
    "                struct_idx = idx\n",
    "                break\n",
    "        if struct_idx is None or struct_idx >= masks.shape[0]:\n",
    "            continue\n",
    "        \n",
    "        mask = masks[struct_idx]\n",
    "        if mask.sum() == 0:\n",
    "            continue\n",
    "        \n",
    "        color = STRUCTURE_COLORS.get(struct_name, 'gray')\n",
    "        gt_x, gt_y = compute_dvh(gt_dose, mask)\n",
    "        pred_x, pred_y = compute_dvh(pred_dose, mask)\n",
    "        \n",
    "        if len(gt_x) > 0:\n",
    "            ax5.plot(gt_x, gt_y, color=color, linestyle='-', linewidth=2, label=f'{struct_name} (GT)')\n",
    "            ax5.plot(pred_x, pred_y, color=color, linestyle='--', linewidth=2, label=f'{struct_name} (Pred)')\n",
    "    \n",
    "    ax5.set_xlabel('Dose (Gy)')\n",
    "    ax5.set_ylabel('Volume (%)')\n",
    "    ax5.set_title('DVH Comparison')\n",
    "    ax5.set_xlim(0, 80)\n",
    "    ax5.set_ylim(0, 105)\n",
    "    ax5.grid(True, alpha=0.3)\n",
    "    ax5.legend(loc='upper right', fontsize=9)\n",
    "    \n",
    "    # Statistics panel\n",
    "    ax6 = fig.add_subplot(gs[1, 2:])\n",
    "    \n",
    "    mask_high = gt_dose > 5\n",
    "    errors = pred_dose[mask_high] - gt_dose[mask_high]\n",
    "    \n",
    "    stats_text = f\"\"\"\n",
    "    Case: {case_data['case_id']}\n",
    "    Model: {model.upper()}\n",
    "    \n",
    "    Overall Metrics:\n",
    "    ---------------------\n",
    "    MAE:  {np.abs(errors).mean():.2f} Gy\n",
    "    RMSE: {np.sqrt((errors**2).mean()):.2f} Gy\n",
    "    \n",
    "    Error Range:\n",
    "    ---------------------\n",
    "    Min:  {errors.min():.2f} Gy\n",
    "    Max:  {errors.max():.2f} Gy\n",
    "    \n",
    "    Error Percentiles:\n",
    "    ---------------------\n",
    "    5th:  {np.percentile(errors, 5):.2f} Gy\n",
    "    95th: {np.percentile(errors, 95):.2f} Gy\n",
    "    \"\"\"\n",
    "    \n",
    "    ax6.text(0.1, 0.5, stats_text, transform=ax6.transAxes,\n",
    "            fontsize=11, verticalalignment='center', fontfamily='monospace',\n",
    "            bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
    "    ax6.axis('off')\n",
    "    ax6.set_title('Statistics')\n",
    "    \n",
    "    fig.suptitle(f'VMAT Dose Prediction Results', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    return fig\n",
    "\n",
    "if case_data and 'ddpm_dose' in case_data:\n",
    "    fig = create_publication_figure(case_data, model='ddpm')\n",
    "    fig.savefig(FIGURES_DIR / f\"{case_data['case_id']}_publication.png\", dpi=300)\n",
    "    fig.savefig(FIGURES_DIR / f\"{case_data['case_id']}_publication.pdf\")\n",
    "    plt.show()\n",
    "    print(f\"Saved publication figure (PNG and PDF)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Generate All Figures for All Cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_all_figures(test_cases: List[str], model: str = 'ddpm') -> None:\n",
    "    \"\"\"Generate standard figure set for all test cases.\"\"\"\n",
    "    \n",
    "    print(f\"Generating figures for {len(test_cases)} cases...\")\n",
    "    \n",
    "    for case_id in test_cases:\n",
    "        print(f\"\\n  Processing {case_id}...\")\n",
    "        \n",
    "        try:\n",
    "            case_data = load_case_data(case_id)\n",
    "            \n",
    "            if f'{model}_dose' not in case_data:\n",
    "                print(f\"    ⚠ No {model} prediction found, skipping\")\n",
    "                continue\n",
    "            \n",
    "            # Dose comparison\n",
    "            fig = plot_dose_comparison(case_data, model=model)\n",
    "            fig.savefig(FIGURES_DIR / f\"{case_id}_dose.png\")\n",
    "            plt.close(fig)\n",
    "            \n",
    "            # DVH\n",
    "            fig = plot_dvh_comparison(case_data, model=model)\n",
    "            fig.savefig(FIGURES_DIR / f\"{case_id}_dvh.png\")\n",
    "            plt.close(fig)\n",
    "            \n",
    "            # Publication figure\n",
    "            fig = create_publication_figure(case_data, model=model)\n",
    "            fig.savefig(FIGURES_DIR / f\"{case_id}_publication.png\", dpi=300)\n",
    "            plt.close(fig)\n",
    "            \n",
    "            print(f\"    ✓ Generated 3 figures\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"    ✗ Error: {e}\")\n",
    "    \n",
    "    print(f\"\\nAll figures saved to: {FIGURES_DIR}\")\n",
    "\n",
    "# Uncomment to generate all figures:\n",
    "# generate_all_figures(test_cases, model='ddpm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Export Summary Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_summary_report(\n",
    "    ddpm_results: Dict,\n",
    "    baseline_results: Dict = None,\n",
    "    output_path: Path = None,\n",
    ") -> str:\n",
    "    \"\"\"Generate markdown summary report.\"\"\"\n",
    "    \n",
    "    if output_path is None:\n",
    "        output_path = FIGURES_DIR / 'summary_report.md'\n",
    "    \n",
    "    lines = [\n",
    "        \"# VMAT Dose Prediction: Results Summary\",\n",
    "        \"\",\n",
    "        f\"Generated: {np.datetime64('now')}\",\n",
    "        \"\",\n",
    "        \"## Model Performance\",\n",
    "        \"\",\n",
    "        \"| Metric | DDPM |\" + (\" Baseline |\" if baseline_results else \"\"),\n",
    "        \"|--------|------|\" + (\"----------|\" if baseline_results else \"\"),\n",
    "    ]\n",
    "    \n",
    "    # MAE\n",
    "    ddpm_mae = f\"{ddpm_results['aggregate_metrics']['mae_gy_mean']:.2f} ± {ddpm_results['aggregate_metrics']['mae_gy_std']:.2f}\"\n",
    "    line = f\"| MAE (Gy) | {ddpm_mae} |\"\n",
    "    if baseline_results:\n",
    "        base_mae = f\"{baseline_results['aggregate_metrics']['mae_gy_mean']:.2f} ± {baseline_results['aggregate_metrics']['mae_gy_std']:.2f}\"\n",
    "        line += f\" {base_mae} |\"\n",
    "    lines.append(line)\n",
    "    \n",
    "    # Gamma\n",
    "    if 'gamma_pass_rate_mean' in ddpm_results['aggregate_metrics']:\n",
    "        ddpm_gamma = f\"{ddpm_results['aggregate_metrics']['gamma_pass_rate_mean']:.1f} ± {ddpm_results['aggregate_metrics']['gamma_pass_rate_std']:.1f}\"\n",
    "        line = f\"| Gamma 3%/3mm (%) | {ddpm_gamma} |\"\n",
    "        if baseline_results and 'gamma_pass_rate_mean' in baseline_results['aggregate_metrics']:\n",
    "            base_gamma = f\"{baseline_results['aggregate_metrics']['gamma_pass_rate_mean']:.1f} ± {baseline_results['aggregate_metrics']['gamma_pass_rate_std']:.1f}\"\n",
    "            line += f\" {base_gamma} |\"\n",
    "        lines.append(line)\n",
    "    \n",
    "    lines.extend([\n",
    "        \"\",\n",
    "        \"## Goal Assessment\",\n",
    "        \"\",\n",
    "        f\"- MAE < 2.0 Gy: {'✓ MET' if ddpm_results['goal_assessment']['mae_goal_met'] else '✗ NOT MET'}\",\n",
    "    ])\n",
    "    \n",
    "    if ddpm_results['goal_assessment'].get('gamma_goal_met') is not None:\n",
    "        lines.append(f\"- Gamma > 95%: {'✓ MET' if ddpm_results['goal_assessment']['gamma_goal_met'] else '✗ NOT MET'}\")\n",
    "    \n",
    "    if 'clinical_constraints' in ddpm_results:\n",
    "        cc = ddpm_results['clinical_constraints']\n",
    "        lines.extend([\n",
    "            \"\",\n",
    "            \"## Clinical Constraints\",\n",
    "            \"\",\n",
    "            f\"- Cases passing all constraints: {cc['cases_all_passed']}/{ddpm_results['n_cases']}\",\n",
    "            f\"- Total violations: {cc['total_violations']}\",\n",
    "        ])\n",
    "        \n",
    "        if cc['violation_counts']:\n",
    "            lines.append(\"\")\n",
    "            lines.append(\"### Most Common Violations\")\n",
    "            lines.append(\"\")\n",
    "            for violation, count in sorted(cc['violation_counts'].items(), key=lambda x: -x[1])[:5]:\n",
    "                lines.append(f\"- {violation}: {count} case(s)\")\n",
    "    \n",
    "    report = \"\\n\".join(lines)\n",
    "    \n",
    "    with open(output_path, 'w') as f:\n",
    "        f.write(report)\n",
    "    \n",
    "    print(f\"Summary report saved to: {output_path}\")\n",
    "    return report\n",
    "\n",
    "if ddpm_results:\n",
    "    report = generate_summary_report(ddpm_results, baseline_results)\n",
    "    print(\"\\n\" + report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "This notebook provides:\n",
    "\n",
    "1. **Model comparison** - Side-by-side metrics tables\n",
    "2. **Per-case analysis** - Identify best/worst cases\n",
    "3. **Dose visualization** - Multi-view, overlay, difference maps\n",
    "4. **DVH analysis** - Curves and metrics tables\n",
    "5. **Clinical constraints** - Pass/fail tracking\n",
    "6. **Error analysis** - Histograms, statistics\n",
    "7. **Publication figures** - Combined, high-DPI outputs\n",
    "8. **Batch processing** - Generate figures for all cases\n",
    "9. **Summary report** - Markdown export\n",
    "\n",
    "All figures are saved to the `figures/` directory."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
