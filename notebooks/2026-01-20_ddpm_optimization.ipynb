{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment: DDPM for Dose Prediction - Training and Optimization\n",
    "\n",
    "**Date:** 2026-01-20  \n",
    "**Experiment IDs:** `ddpm_dose_v1`, `phase1_sampling`, `phase1_ensemble`  \n",
    "**Status:** Complete  \n",
    "**Git Commit:** `3efbea0` (DDPM training)  \n",
    "\n",
    "---\n",
    "\n",
    "## 1. Overview\n",
    "\n",
    "### 1.1 Objective\n",
    "\n",
    "Evaluate whether Denoising Diffusion Probabilistic Models (DDPM) can improve dose prediction accuracy compared to a simple baseline U-Net.\n",
    "\n",
    "**Hypothesis:** The iterative denoising process of diffusion models will capture complex dose distributions better than direct regression.\n",
    "\n",
    "### 1.2 Key Results\n",
    "\n",
    "| Metric | DDPM (training) | DDPM (optimized) | Baseline |\n",
    "|--------|-----------------|------------------|----------|\n",
    "| **Val MAE** | 12.19 Gy | **3.78 Gy** | 3.73 Gy |\n",
    "| Optimal steps | - | 50 | N/A |\n",
    "| Training time | 1.94 hours | - | 2.55 hours |\n",
    "\n",
    "### 1.3 Conclusion\n",
    "\n",
    "**DDPM is NOT recommended for dose prediction.** Key findings:\n",
    "1. **\"More steps = worse\"** - Counter-intuitive result indicating structural issue\n",
    "2. **No benefit over baseline** - Optimized DDPM (3.78 Gy) matches baseline (3.73 Gy)\n",
    "3. **Near-zero sample variability** - Model is deterministic, not generative\n",
    "4. **High complexity, no payoff** - 1000 timesteps, iterative sampling for equivalent results\n",
    "\n",
    "**Recommendation:** Use baseline U-Net with gradient loss instead."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Reproducibility Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "REPRODUCIBILITY_INFO = {\n",
    "    'git_commit_training': '3efbea0',\n",
    "    'git_commit_optimization': '206f84c',\n",
    "    'python_version': '3.12.12',\n",
    "    'pytorch_version': '2.6.0+cu124',\n",
    "    'cuda_version': '12.4',\n",
    "    'gpu': 'NVIDIA GeForce RTX 3090 (24 GB)',\n",
    "    'random_seed': 42,\n",
    "    'experiment_date': '2026-01-19 to 2026-01-20',\n",
    "    'training_script': 'scripts/train_dose_ddpm_v2.py',\n",
    "    'figure_script': 'scripts/generate_ddpm_figures.py',\n",
    "}\n",
    "\n",
    "print('Reproducibility Information:')\n",
    "for k, v in REPRODUCIBILITY_INFO.items():\n",
    "    print(f'  {k}: {v}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Command to Reproduce\n",
    "\n",
    "```bash\n",
    "# Checkout correct commit\n",
    "git checkout 3efbea0\n",
    "\n",
    "# Activate environment (Windows)\n",
    "call C:\\pinokio\\bin\\miniconda\\Scripts\\activate.bat vmat-win\n",
    "cd C:\\Users\\Bill\\vmat-diffusion-project\n",
    "\n",
    "# Train DDPM\n",
    "python scripts\\train_dose_ddpm_v2.py \\\n",
    "    --data_dir I:\\processed_npz \\\n",
    "    --epochs 200 \\\n",
    "    --batch_size 1\n",
    "\n",
    "# Generate figures\n",
    "python scripts\\generate_ddpm_figures.py\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_INFO = {\n",
    "    'total_cases': 23,\n",
    "    'train_cases': 19,\n",
    "    'val_cases': 2,\n",
    "    'test_cases': 2,\n",
    "    'val_case_ids': ['case_0011', 'case_0016'],\n",
    "    'test_case_ids': ['case_0007', 'case_0021'],\n",
    "    'preprocessing_version': 'v2.2.0',\n",
    "    'data_location': 'I:\\\\processed_npz',\n",
    "    'split_seed': 42,\n",
    "}\n",
    "\n",
    "print('Dataset Information:')\n",
    "for k, v in DATASET_INFO.items():\n",
    "    print(f'  {k}: {v}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. Model / Method\n",
    "\n",
    "### 4.1 DDPM Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_CONFIG = {\n",
    "    'architecture': 'SimpleUNet3D (DDPM)',\n",
    "    'parameters': '23,705,857 (23.7M)',\n",
    "    'in_channels': 10,  # 9 anatomy + 1 noisy dose\n",
    "    'out_channels': 1,\n",
    "    'base_channels': 48,\n",
    "    'timesteps': 1000,\n",
    "    'noise_schedule': 'cosine',\n",
    "    'sampling_method': 'DDIM',\n",
    "}\n",
    "\n",
    "print('Model Configuration:')\n",
    "for k, v in MODEL_CONFIG.items():\n",
    "    print(f'  {k}: {v}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 DDPM Approach\n",
    "\n",
    "The DDPM approach:\n",
    "1. **Forward process:** Gradually add noise to ground truth dose over T=1000 timesteps\n",
    "2. **Training:** Learn to predict the noise added at each timestep\n",
    "3. **Inference:** Start from pure noise, iteratively denoise to recover dose\n",
    "\n",
    "**Key difference from baseline:** DDPM predicts noise, not dose directly. The dose is recovered by iterative denoising."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. Training Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINING_CONFIG = {\n",
    "    'max_epochs': 200,\n",
    "    'actual_epochs': 37,\n",
    "    'early_stopping_patience': 20,\n",
    "    'batch_size': 1,\n",
    "    'patch_size': 128,\n",
    "    'learning_rate': 1e-4,\n",
    "    'optimizer': 'AdamW',\n",
    "    'weight_decay': 0.01,\n",
    "    'loss_function': 'MSE (noise prediction)',\n",
    "    'precision': '16-mixed',\n",
    "    'gradient_clip': 1.0,\n",
    "    'training_time': '1.94 hours',\n",
    "}\n",
    "\n",
    "print('Training Configuration:')\n",
    "for k, v in TRAINING_CONFIG.items():\n",
    "    print(f'  {k}: {v}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. Results\n",
    "\n",
    "### 6.1 Training Curves - Volatile MAE\n",
    "\n",
    "![DDPM Training Curves](../runs/vmat_dose_ddpm/figures/fig1_ddpm_training_curves.png)\n",
    "\n",
    "**Figure 1:** (A) Training loss decreases steadily as expected. (B) Validation MAE is **extremely volatile** (range: 12-64 Gy), indicating the noise prediction loss doesn't correlate well with dose accuracy.\n",
    "\n",
    "**Key observation:** The model learns denoising well (loss decreases) but produces unstable dose predictions during training validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Phase 1: Sampling Steps Ablation\n",
    "\n",
    "![Sampling Steps Ablation](../runs/vmat_dose_ddpm/figures/fig2_sampling_steps_ablation.png)\n",
    "\n",
    "**Figure 2:** (A) **Critical finding: More steps = worse MAE.** 50 DDIM steps achieves 3.80 Gy; 1000 steps gives 6.73 Gy (77% worse!). (B) Inference time scales linearly with steps.\n",
    "\n",
    "| Steps | MAE (Gy) | Time (min) | vs Baseline |\n",
    "|-------|----------|------------|-------------|\n",
    "| 50 | **3.80** | 6.6 | +1.9% |\n",
    "| 100 | 4.89 | 13.5 | +31% |\n",
    "| 250 | 5.24 | 32.8 | +41% |\n",
    "| 500 | 5.93 | 65.3 | +59% |\n",
    "| 1000 | 6.73 | 130.5 | +80% |\n",
    "\n",
    "**Interpretation:** The model denoises away the dose signal with more steps. This indicates a fundamental structural issue - the model isn't learning to generate dose distributions, it's learning to denoise noise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 Phase 1: Ensemble Averaging\n",
    "\n",
    "![Ensemble Averaging](../runs/vmat_dose_ddpm/figures/fig3_ensemble_averaging.png)\n",
    "\n",
    "**Figure 3:** (A) Ensemble averaging provides no benefit (n=1 is optimal). (B) Sample variability is near-zero (~0.02), indicating the model is essentially deterministic despite being a \"generative\" model.\n",
    "\n",
    "| Ensemble Size | MAE (Gy) | Sample Std |\n",
    "|---------------|----------|------------|\n",
    "| 1 | **3.775** | 0.00 |\n",
    "| 3 | 3.835 | 0.02 |\n",
    "| 5 | 3.830 | 0.02 |\n",
    "| 10 | 3.835 | 0.03 |\n",
    "\n",
    "**Interpretation:** If diffusion models excel at multi-modal generation, we'd expect sample diversity. The near-zero variability confirms dose prediction is deterministic (one correct answer per patient), making diffusion's generative capability irrelevant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.4 Key Finding Summary\n",
    "\n",
    "![Key Finding](../runs/vmat_dose_ddpm/figures/fig5_key_finding.png)\n",
    "\n",
    "**Figure 5:** Summary visualization showing DDPM consistently underperforms or matches baseline. Even the optimal DDPM configuration (50 steps, n=1) only matches the baseline, while adding significant complexity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.5 Model Comparison\n",
    "\n",
    "![Model Comparison](../runs/vmat_dose_ddpm/figures/fig4_model_comparison.png)\n",
    "\n",
    "**Figure 4:** Final comparison of all models tested. Gradient loss achieves the best results (3.67 Gy) while DDPM provides no benefit over baseline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.6 Quantitative Results Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULTS = {\n",
    "    'ddpm_training_best_mae_gy': 12.19,\n",
    "    'ddpm_training_best_epoch': 15,\n",
    "    'ddpm_optimized_mae_gy': 3.78,\n",
    "    'ddpm_optimal_steps': 50,\n",
    "    'ddpm_optimal_ensemble': 1,\n",
    "    'baseline_mae_gy': 3.73,\n",
    "    'gradient_loss_mae_gy': 3.67,\n",
    "    'ddpm_training_time_hours': 1.94,\n",
    "    'ddpm_inference_time_50_steps_min': 6.6,\n",
    "}\n",
    "\n",
    "print('Quantitative Results:')\n",
    "for k, v in RESULTS.items():\n",
    "    print(f'  {k}: {v}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 7. Analysis\n",
    "\n",
    "### 7.1 Why DDPM Failed for Dose Prediction\n",
    "\n",
    "| Red Flag | Implication |\n",
    "|----------|-------------|\n",
    "| More steps = worse results | Model denoises away dose signal |\n",
    "| Near-zero sample variability | Model is deterministic, not generative |\n",
    "| DDPM = Baseline accuracy | Added complexity provides no benefit |\n",
    "| 50/1000 steps optimal | Essentially one-shot prediction |\n",
    "\n",
    "### 7.2 Fundamental Mismatch\n",
    "\n",
    "**Diffusion models excel at multi-modal generation** (many valid outputs for one input):\n",
    "- Image generation: Many valid images for \"a cat\"\n",
    "- Audio synthesis: Many valid waveforms for \"hello\"\n",
    "\n",
    "**Dose prediction is deterministic** (one correct answer per patient):\n",
    "- Given patient anatomy and prescription, there's ONE optimal dose distribution\n",
    "- No benefit from sampling multiple outputs\n",
    "- The \"generative\" capability is wasted\n",
    "\n",
    "### 7.3 Limitations\n",
    "\n",
    "1. **Small dataset:** 23 cases may not be enough for diffusion models to learn\n",
    "2. **Architecture:** SimpleUNet3D may not be optimal for diffusion\n",
    "3. **Hyperparameters:** Only tested cosine schedule, DDIM sampling\n",
    "\n",
    "However, the \"more steps = worse\" finding suggests a fundamental issue that more data or tuning won't fix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 8. Conclusions\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "1. **DDPM is NOT recommended** for dose prediction - no benefit over baseline\n",
    "2. **\"More steps = worse\"** indicates structural issue, not just tuning problem\n",
    "3. **Dose prediction is deterministic** - diffusion's generative strength is irrelevant\n",
    "4. **Use gradient loss instead** - achieves 3.67 Gy MAE and 27.9% Gamma (best so far)\n",
    "\n",
    "### Strategic Recommendation\n",
    "\n",
    "Abandon DDPM approach. Focus on:\n",
    "1. **Gradient loss baseline** (current best)\n",
    "2. **VGG perceptual loss** (Phase B)\n",
    "3. **Flow Matching** if generative approach desired (simpler than diffusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 9. Next Steps\n",
    "\n",
    "- [x] Complete DDPM training and optimization\n",
    "- [x] Document findings and create figures\n",
    "- [x] Complete gradient loss experiment (see separate notebook)\n",
    "- [ ] **Phase B:** Gradient + VGG combined loss\n",
    "- [ ] Consider Flow Matching as alternative generative approach\n",
    "- [ ] Re-evaluate with 100+ cases when available"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 10. Artifacts\n",
    "\n",
    "| Artifact | Path |\n",
    "|----------|------|\n",
    "| DDPM Checkpoint | `runs/vmat_dose_ddpm/checkpoints/best-epoch=015-val/mae_gy=12.19.ckpt` |\n",
    "| Training Metrics | `runs/vmat_dose_ddpm/epoch_metrics.csv` |\n",
    "| Training Config | `runs/vmat_dose_ddpm/training_config.json` |\n",
    "| Sampling Results | `experiments/phase1_sampling/exp1_1_sampling_results.json` |\n",
    "| Ensemble Results | `experiments/phase1_ensemble/exp1_2_ensemble_results.json` |\n",
    "| Figures (PNG) | `runs/vmat_dose_ddpm/figures/*.png` |\n",
    "| Figures (PDF) | `runs/vmat_dose_ddpm/figures/*.pdf` |\n",
    "| Figure Script | `scripts/generate_ddpm_figures.py` |\n",
    "\n",
    "---\n",
    "\n",
    "*Notebook created: 2026-01-20*  \n",
    "*Last updated: 2026-01-20*  \n",
    "*Git commit (DDPM training): `3efbea0`*  \n",
    "*Git commit (optimization): `206f84c`*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
