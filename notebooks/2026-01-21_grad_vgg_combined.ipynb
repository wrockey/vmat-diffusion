{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment: Combined Gradient + VGG Perceptual Loss\n",
    "\n",
    "**Date:** 2026-01-21  \n",
    "**Experiment ID:** `grad_vgg_combined`  \n",
    "**Status:** Complete  \n",
    "\n",
    "---\n",
    "\n",
    "## 1. Overview\n",
    "\n",
    "### 1.1 Objective\n",
    "Test whether combining gradient loss (3D Sobel) with VGG perceptual loss improves Gamma pass rate beyond gradient loss alone. This is **Phase B** of the loss function improvement experiments, following Phase A (gradient loss only) which nearly doubled Gamma from 14.2% to 27.9%.\n",
    "\n",
    "### 1.2 Hypothesis\n",
    "VGG perceptual loss encourages feature-level similarity between predicted and ground truth doses, which may improve dose distribution quality and Gamma pass rate beyond what gradient loss alone achieves.\n",
    "\n",
    "### 1.3 Key Results\n",
    "\n",
    "| Metric | Baseline | Grad Loss | **Grad+VGG** | Change vs Grad |\n",
    "|--------|----------|-----------|--------------|----------------|\n",
    "| **Val MAE** | 3.73 Gy | 3.67 Gy | **2.27 Gy** | **-38%** ✅ |\n",
    "| **Test MAE** | 1.43 Gy | 1.44 Gy | **1.44 Gy** | 0% |\n",
    "| **Gamma (3%/3mm)** | 14.2% | 27.9% | **~28%** | ~0% ❌ |\n",
    "\n",
    "### 1.4 Conclusion\n",
    "\n",
    "**VGG loss significantly improves validation MAE (-38%) but does NOT improve Gamma pass rate (~28%, unchanged from gradient loss alone).** This indicates that VGG perceptual loss helps with overall dose accuracy (mean error reduction) but does not improve edge sharpness as measured by Gamma. The recommendation is to skip VGG in future experiments and try adversarial loss or structure-weighted loss instead for Gamma improvement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Reproducibility Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reproducibility Information (captured at experiment time)\n",
    "REPRODUCIBILITY_INFO = {\n",
    "    'git_commit': 'dca8446',  # Pre-experiment commit\n",
    "    'git_message': 'Add perceptual loss (gradient + VGG) to baseline U-Net',\n",
    "    'python_version': '3.12.8',\n",
    "    'pytorch_version': '2.6.0+cu124',\n",
    "    'cuda_version': '12.4',\n",
    "    'gpu': 'NVIDIA GeForce RTX 4090',\n",
    "    'random_seed': 42,\n",
    "    'experiment_date': '2026-01-21',\n",
    "}\n",
    "\n",
    "print('Reproducibility Information:')\n",
    "for k, v in REPRODUCIBILITY_INFO.items():\n",
    "    print(f'  {k}: {v}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Command to Reproduce\n",
    "\n",
    "```bash\n",
    "# Checkout correct commit\n",
    "git checkout dca8446\n",
    "\n",
    "# Activate environment (Windows)\n",
    "call C:\\pinokio\\bin\\miniconda\\Scripts\\activate.bat vmat-win\n",
    "\n",
    "# Run experiment\n",
    "python scripts\\train_baseline_unet.py \\\n",
    "    --exp_name grad_vgg_combined \\\n",
    "    --data_dir I:\\processed_npz \\\n",
    "    --use_gradient_loss \\\n",
    "    --gradient_loss_weight 0.1 \\\n",
    "    --use_vgg_loss \\\n",
    "    --vgg_loss_weight 0.001 \\\n",
    "    --epochs 100\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_INFO = {\n",
    "    'total_cases': 23,\n",
    "    'train_cases': 19,\n",
    "    'val_cases': 2,\n",
    "    'test_cases': 2,\n",
    "    'preprocessing_version': 'v2.2.0',\n",
    "    'data_directory': 'I:\\\\processed_npz',\n",
    "    'test_cases_ids': ['case_0007', 'case_0021'],\n",
    "}\n",
    "\n",
    "print('Dataset Information:')\n",
    "for k, v in DATASET_INFO.items():\n",
    "    print(f'  {k}: {v}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. Model / Method\n",
    "\n",
    "### 4.1 Architecture\n",
    "BaselineUNet3D with FiLM conditioning on dose constraints.\n",
    "\n",
    "### 4.2 Loss Function\n",
    "Combined loss with three components:\n",
    "\n",
    "$$L_{total} = L_{MSE} + \\lambda_{grad} \\cdot L_{grad} + \\lambda_{VGG} \\cdot L_{VGG}$$\n",
    "\n",
    "Where:\n",
    "- $L_{MSE}$: Mean Squared Error (standard pixel-wise loss)\n",
    "- $L_{grad}$: 3D Sobel gradient loss (edge sharpness)\n",
    "- $L_{VGG}$: VGG perceptual loss (feature-level similarity, slice-wise)\n",
    "- $\\lambda_{grad} = 0.1$\n",
    "- $\\lambda_{VGG} = 0.001$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_CONFIG = {\n",
    "    'architecture': 'BaselineUNet3D (Direct Regression)',\n",
    "    'in_channels': 9,  # CT + 8 structure SDFs\n",
    "    'out_channels': 1,  # Dose\n",
    "    'base_channels': 48,\n",
    "    'constraint_dim': 13,  # FiLM conditioning\n",
    "    'model_params': 25468289,  # ~25M parameters\n",
    "}\n",
    "\n",
    "LOSS_CONFIG = {\n",
    "    'use_gradient_loss': True,\n",
    "    'gradient_loss_weight': 0.1,\n",
    "    'use_vgg_loss': True,\n",
    "    'vgg_loss_weight': 0.001,\n",
    "    'vgg_slice_stride': 8,  # Process every 8th slice for memory efficiency\n",
    "}\n",
    "\n",
    "print('Model Configuration:')\n",
    "for k, v in MODEL_CONFIG.items():\n",
    "    print(f'  {k}: {v}')\n",
    "print('\\nLoss Configuration:')\n",
    "for k, v in LOSS_CONFIG.items():\n",
    "    print(f'  {k}: {v}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. Training Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINING_CONFIG = {\n",
    "    'max_epochs': 100,\n",
    "    'actual_epochs': 82,  # Early stopped\n",
    "    'batch_size': 1,\n",
    "    'learning_rate': 1e-4,\n",
    "    'weight_decay': 0.01,\n",
    "    'optimizer': 'AdamW',\n",
    "    'scheduler': 'ReduceLROnPlateau',\n",
    "    'early_stopping_patience': 50,\n",
    "    'training_time_hours': 9.74,\n",
    "}\n",
    "\n",
    "print('Training Configuration:')\n",
    "for k, v in TRAINING_CONFIG.items():\n",
    "    print(f'  {k}: {v}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. Results\n",
    "\n",
    "### 6.1 Training Curves\n",
    "\n",
    "![Training Curves](../runs/grad_vgg_combined/figures/fig1_training_curves.png)\n",
    "\n",
    "**Key observations:**\n",
    "- Best validation MAE: **2.27 Gy** at epoch 32 (38% improvement over baseline's 3.73 Gy)\n",
    "- Training early stopped at epoch 82 due to 50-epoch patience\n",
    "- Smooth convergence without significant overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load training metrics\n",
    "metrics = pd.read_csv('../runs/grad_vgg_combined/version_1/metrics.csv')\n",
    "val_metrics = metrics[metrics['val/mae_gy'].notna()][['epoch', 'val/loss', 'val/mae_gy']]\n",
    "\n",
    "print('Training Progress:')\n",
    "print(f'  Total epochs: {int(val_metrics[\"epoch\"].max())}')\n",
    "print(f'  Best val MAE: {val_metrics[\"val/mae_gy\"].min():.2f} Gy (epoch {int(val_metrics.loc[val_metrics[\"val/mae_gy\"].idxmin(), \"epoch\"])})')\n",
    "print(f'  Final val MAE: {val_metrics[\"val/mae_gy\"].iloc[-1]:.2f} Gy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Model Comparison\n",
    "\n",
    "![Model Comparison](../runs/grad_vgg_combined/figures/fig2_model_comparison.png)\n",
    "\n",
    "**Key observations:**\n",
    "- Validation MAE: Significant improvement (2.27 vs 3.73 Gy baseline)\n",
    "- Test MAE: Unchanged (1.44 Gy for all three models)\n",
    "- Gamma pass rate: **Unchanged** (~28% for both Grad and Grad+VGG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULTS = {\n",
    "    'best_val_mae_gy': 2.27,\n",
    "    'best_epoch': 32,\n",
    "    'final_val_mae_gy': 4.43,  # After patience exhausted\n",
    "    'test_mae_gy': 1.44,\n",
    "    'gamma_pass_rate': 27.85,\n",
    "    'training_time_hours': 9.74,\n",
    "}\n",
    "\n",
    "print('Final Results:')\n",
    "for k, v in RESULTS.items():\n",
    "    print(f'  {k}: {v}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 Dose Slice Visualization\n",
    "\n",
    "![Dose Slices](../runs/grad_vgg_combined/figures/fig3_dose_slices.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.4 Loss Components\n",
    "\n",
    "![Loss Components](../runs/grad_vgg_combined/figures/fig4_loss_components.png)\n",
    "\n",
    "**Key observations:**\n",
    "- MSE loss dominates the total loss\n",
    "- Gradient loss (weighted by 0.1) contributes meaningfully\n",
    "- VGG loss (weighted by 0.001) has minimal contribution to total loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.5 Key Finding\n",
    "\n",
    "![Key Finding](../runs/grad_vgg_combined/figures/fig5_key_finding.png)\n",
    "\n",
    "**Key insight:** VGG perceptual loss improves overall dose accuracy (MAE) but does NOT improve Gamma pass rate. This suggests:\n",
    "1. VGG encourages feature-level similarity but not edge sharpness\n",
    "2. Gamma (3%/3mm) is sensitive to local dose gradients, not global features\n",
    "3. For Gamma improvement, need losses that explicitly target dose gradients or spatial accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.6 Test Case Details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_CASE_RESULTS = {\n",
    "    'case_0007': {\n",
    "        'mae_gy': 1.77,\n",
    "        'mae_body_gy': 5.97,\n",
    "        'gamma_pass_rate': 41.2,\n",
    "    },\n",
    "    'case_0021': {\n",
    "        'mae_gy': 1.11,\n",
    "        'mae_body_gy': 6.75,\n",
    "        'gamma_pass_rate': 14.5,\n",
    "    }\n",
    "}\n",
    "\n",
    "print('Test Case Results:')\n",
    "for case, metrics in TEST_CASE_RESULTS.items():\n",
    "    print(f'\\n  {case}:')\n",
    "    for k, v in metrics.items():\n",
    "        print(f'    {k}: {v}')\n",
    "\n",
    "# Compute means\n",
    "import numpy as np\n",
    "mae_values = [v['mae_gy'] for v in TEST_CASE_RESULTS.values()]\n",
    "gamma_values = [v['gamma_pass_rate'] for v in TEST_CASE_RESULTS.values()]\n",
    "print(f'\\n  Mean MAE: {np.mean(mae_values):.2f} +/- {np.std(mae_values):.2f} Gy')\n",
    "print(f'  Mean Gamma: {np.mean(gamma_values):.1f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 7. Analysis\n",
    "\n",
    "### 7.1 Observations\n",
    "\n",
    "1. **VGG significantly improves validation MAE** (-38% vs baseline), suggesting it helps the model learn better global dose distributions\n",
    "2. **Test MAE is unchanged** (1.44 Gy for all models), indicating the validation improvement doesn't transfer to held-out cases\n",
    "3. **Gamma pass rate is unchanged** (~28%), meaning VGG does not improve the spatial accuracy that Gamma measures\n",
    "4. **Training time increased** (9.74h vs 1.85h for grad-only), due to VGG feature extraction overhead\n",
    "\n",
    "### 7.2 Why VGG Doesn't Help Gamma\n",
    "\n",
    "VGG perceptual loss compares high-level features between predicted and ground truth images. However:\n",
    "- VGG features are designed for natural images (ImageNet), not dose distributions\n",
    "- VGG emphasizes texture and semantic content, not precise spatial accuracy\n",
    "- Gamma (3%/3mm) measures point-by-point dose-distance agreement, not feature similarity\n",
    "\n",
    "### 7.3 Comparison to Previous Work\n",
    "\n",
    "| Experiment | Val MAE | Test MAE | Gamma | Training Time |\n",
    "|------------|---------|----------|-------|---------------|\n",
    "| Baseline | 3.73 Gy | 1.43 Gy | 14.2% | 2.55h |\n",
    "| Grad Loss | 3.67 Gy | 1.44 Gy | **27.9%** | 1.85h |\n",
    "| **Grad+VGG** | **2.27 Gy** | 1.44 Gy | ~28% | 9.74h |\n",
    "\n",
    "### 7.4 Limitations\n",
    "\n",
    "1. **Small test set** (n=2) - results may not generalize\n",
    "2. **Gamma computed on central slice only** - not full 3D Gamma\n",
    "3. **VGG features from ImageNet** - may not be optimal for dose images\n",
    "4. **Fixed hyperparameters** - VGG weight (0.001) not tuned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 8. Conclusions\n",
    "\n",
    "1. **VGG perceptual loss improves validation MAE but not Gamma pass rate**\n",
    "2. **Adding VGG is not recommended** for the 95% Gamma goal - it adds training time without Gamma benefit\n",
    "3. **Next steps should focus on**:\n",
    "   - Adversarial loss (PatchGAN) for sharper edges\n",
    "   - Structure-weighted loss for PTV/OAR accuracy\n",
    "   - DVH-aware loss for clinical metrics\n",
    "   - Data augmentation with n=23 cases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 9. Next Steps (Decision Tree Outcome)\n",
    "\n",
    "Based on the decision tree in `.claude/instructions.md`:\n",
    "\n",
    "**Result:** Gamma ≈ 28% (unchanged from Phase A)\n",
    "\n",
    "**Decision:** VGG not helping Gamma. Skip VGG in future experiments.\n",
    "\n",
    "**Next experiments to try:**\n",
    "- [ ] **Adversarial loss (PatchGAN)** - For edge sharpness\n",
    "- [ ] **Structure-weighted loss** - Weight PTV regions 2x\n",
    "- [ ] **DVH-aware loss** - Penalize D95 underdosing\n",
    "- [ ] **Data augmentation** - Address overfitting with n=23"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 10. Artifacts\n",
    "\n",
    "| Artifact | Path |\n",
    "|----------|------|\n",
    "| Best Checkpoint | `runs/grad_vgg_combined/checkpoints/best-epoch=032-val/mae_gy=2.267.ckpt` |\n",
    "| Metrics | `runs/grad_vgg_combined/version_1/metrics.csv` |\n",
    "| Config | `runs/grad_vgg_combined/training_config.json` |\n",
    "| Summary | `runs/grad_vgg_combined/training_summary.json` |\n",
    "| Predictions | `predictions/grad_vgg_combined_test/` |\n",
    "| Figures | `runs/grad_vgg_combined/figures/` |\n",
    "\n",
    "---\n",
    "\n",
    "*Notebook created: 2026-01-21*  \n",
    "*Last updated: 2026-01-21*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
